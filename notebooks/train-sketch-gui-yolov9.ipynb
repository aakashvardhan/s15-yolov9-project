{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPYrbOhZReGwoictxHSDOkq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training YOLOv9 model on Sketch GUI Images"],"metadata":{"id":"oxEtAdHG0lsk"}},{"cell_type":"markdown","source":["## Setup & Download"],"metadata":{"id":"WdDL9SDP0rqi"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"RgiOEi560NCj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720701876499,"user_tz":-240,"elapsed":542,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"aea4663b-fe17-4d69-9bec-f5770b41b008"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jul 11 12:44:36 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["import os\n","HOME = os.getcwd()\n","print(HOME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RFcB_TQ0vRR","executionInfo":{"status":"ok","timestamp":1720701901674,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"023c1b67-2a17-43d5-df83-6f740c91aa07"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# Cloning YOLOv9 library\n","!git clone --quiet https://github.com/WongKinYiu/yolov9.git"],"metadata":{"id":"n0KYNN9z01ho","executionInfo":{"status":"ok","timestamp":1720702002659,"user_tz":-240,"elapsed":1961,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install -q -r yolov9/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fokef9y1Nt8","executionInfo":{"status":"ok","timestamp":1720702080887,"user_tz":-240,"elapsed":59604,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"3bd57d29-6f41-46ca-a58b-206d427ee9bc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Cloning my repo\n","!git clone --quiet https://github.com/aakashvardhan/s15-yolov9-project.git"],"metadata":{"id":"esLpl3oO1Sv8","executionInfo":{"status":"ok","timestamp":1720702143734,"user_tz":-240,"elapsed":2719,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Downloading Weights"],"metadata":{"id":"a8-2oK331xc5"}},{"cell_type":"code","source":["!python {HOME}/s15-yolov9-project/download_weights.py"],"metadata":{"id":"3b1xKEoc1v-8","executionInfo":{"status":"ok","timestamp":1720702205334,"user_tz":-240,"elapsed":6274,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!ls -la {HOME}/weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbvnm15y1-Jp","executionInfo":{"status":"ok","timestamp":1720702237393,"user_tz":-240,"elapsed":711,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"9157c336-e0c9-49c7-87f9-c9419026cdaa"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["total 237680\n","drwxr-xr-x 2 root root      4096 Jul 11 12:50 .\n","drwxr-xr-x 1 root root      4096 Jul 11 12:49 ..\n","-rw-r--r-- 1 root root 103153312 Jul 11 12:50 yolov9-c.pt\n","-rw-r--r-- 1 root root 140217688 Jul 11 12:50 yolov9-e.pt\n"]}]},{"cell_type":"markdown","source":["### Downloading Dataset"],"metadata":{"id":"eKsdJ2JG2K-f"}},{"cell_type":"markdown","source":["*Modified paths in data.yaml file\n","\n","***\n","\n","train: ../data/sketch_images/train \\\n","val: ../data/sketch_images/valid \\\n","test: ../data/sketch_images/test"],"metadata":{"id":"dwV6NJO15omO"}},{"cell_type":"code","source":["!python {HOME}/s15-yolov9-project/download_sketch_dataset.py"],"metadata":{"id":"rWEUE2XO2HVd","executionInfo":{"status":"ok","timestamp":1720702296648,"user_tz":-240,"elapsed":4777,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["%mv {HOME}/sketch_images {HOME}/yolov9/data"],"metadata":{"id":"2gSQ6y082Uzd","executionInfo":{"status":"ok","timestamp":1720702366167,"user_tz":-240,"elapsed":514,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"o3RO4YS53Ml4"}},{"cell_type":"markdown","source":["*Changed value of nc to 8 in yolo9-e.yaml and yolo9-c.yaml and moved it to weights folder"],"metadata":{"id":"Vjsnx5iD3DTb"}},{"cell_type":"code","source":["%mv {HOME}/yolov9/models/detect/yolov9-e.yaml {HOME}/weights"],"metadata":{"id":"vgEZ7Gz32m00","executionInfo":{"status":"ok","timestamp":1720702587911,"user_tz":-240,"elapsed":494,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["%mv {HOME}/yolov9/models/detect/yolov9-c.yaml {HOME}/weights"],"metadata":{"id":"Q6gciNqg3RPb","executionInfo":{"status":"ok","timestamp":1720702633323,"user_tz":-240,"elapsed":885,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Execute Training Script\n","!python {HOME}/yolov9/train_dual.py \\\n","--workers 8 --batch 8  --img 640 --epochs 50 \\\n","--data {HOME}/yolov9/data/sketch_images/data.yaml \\\n","--weights {HOME}/weights/yolov9-e.pt \\\n","--cfg {HOME}/weights/yolov9-e.yaml \\\n","--device 0 \\\n","--hyp {HOME}/yolov9/data/hyps/hyp.scratch-high.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86ENIEYq3n9R","outputId":"c7da394c-09f6-4b96-fb84-d37004797dc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-07-11 13:13:01.111882: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-11 13:13:01.111938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-11 13:13:01.113230: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-07-11 13:13:01.120451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-07-11 13:13:02.303486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/yolov9-e.pt, cfg=/content/weights/yolov9-e.yaml, data=/content/yolov9/data/sketch_images/data.yaml, hyp=/content/yolov9/data/hyps/hyp.scratch-high.yaml, epochs=50, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov9/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=0, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","YOLO 🚀 v0.1-104-g5b1ea9a Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov9/runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.Silence                   []                            \n","  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n","  4                -1  1    164352  models.common.ADown                     [256, 256]                    \n","  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n","  6                -1  1    656384  models.common.ADown                     [512, 512]                    \n","  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n","  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n","  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    \n"," 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              \n"," 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         \n"," 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   \n"," 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]\n"," 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n"," 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             \n"," 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n"," 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                \n"," 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        \n"," 20                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   \n"," 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       \n"," 23                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      \n"," 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      \n"," 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  \n"," 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         \n"," 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     \n"," 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 31           [-1, 7]  1         0  models.common.Concat                    [1]                           \n"," 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 34           [-1, 5]  1         0  models.common.Concat                    [1]                           \n"," 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              \n"," 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 38          [-1, 25]  1         0  models.common.Concat                    [1]                           \n"," 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      \n"," 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 41          [-1, 22]  1         0  models.common.Concat                    [1]                           \n"," 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      \n"," 43                -1  1    164352  models.common.ADown                     [256, 256]                    \n"," 44          [-1, 39]  1         0  models.common.Concat                    [1]                           \n"," 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       \n"," 46                -1  1    656384  models.common.ADown                     [512, 512]                    \n"," 47          [-1, 36]  1         0  models.common.Concat                    [1]                           \n"," 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     \n"," 49[35, 32, 29, 42, 45, 48]  1  10993616  models.yolo.DualDDetect                 [8, [256, 512, 512, 256, 512, 512]]\n","yolov9-e summary: 1475 layers, 69418640 parameters, 69418608 gradients, 244.9 GFLOPs\n","\n","Transferred 2160/2172 items from /content/weights/yolov9-e.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.0005), 373 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9/data/sketch_images/train/labels.cache... 934 images, 0 backgrounds, 0 corrupt: 100% 934/934 [00:00<?, ?it/s]\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9/data/sketch_images/valid/labels.cache... 152 images, 0 backgrounds, 0 corrupt: 100% 152/152 [00:00<?, ?it/s]\n","Plotting labels to yolov9/runs/train/exp6/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1myolov9/runs/train/exp6\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       0/49      13.1G      2.189      5.434      1.869        520        640:   0% 0/117 [00:03<?, ?it/s]WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n","       0/49      15.4G      1.925      3.713      1.696        271        640:  44% 51/117 [01:07<01:07,  1.03s/it]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5vg32O5L5fhR"},"execution_count":null,"outputs":[]}]}